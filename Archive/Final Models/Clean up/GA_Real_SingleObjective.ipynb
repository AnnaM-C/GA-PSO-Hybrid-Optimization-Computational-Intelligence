{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9QALPGkCaUs"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sympy.combinatorics.graycode import GrayCode\n",
        "from sympy.combinatorics.graycode import gray_to_bin\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "# !pip install deap\n",
        "from deap import creator\n",
        "from deap import base\n",
        "from deap import tools\n",
        "from deap import algorithms\n",
        "from deap import benchmarks\n",
        "import torch\n",
        "import random\n",
        "import array\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "# Load Dataset\n",
        "batch_size = 10000\n",
        "\n",
        "transform   = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # Function to transform the dataset to the specified range\n",
        "\n",
        "trainset      = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader   = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset       = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader    = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "classes       = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Device, \", device)\n",
        "\n",
        "totalImages   = len(trainloader.dataset)\n",
        "miniAmount    = 1000\n",
        "numOfLoaders  = totalImages // miniAmount\n",
        "\n",
        "print(\"Number of loaders to create: \" + str(numOfLoaders))\n",
        "\n",
        "miniLoaders = []\n",
        "\n",
        "for i in range(numOfLoaders):\n",
        "  startIdx        = i * miniAmount\n",
        "  endIdx          = (i + 1) * miniAmount if i < numOfLoaders - 1 else totalImages\n",
        "  subset          = torch.utils.data.Subset(trainset, range(startIdx, endIdx))\n",
        "  SubTrainLoader  = torch.utils.data.DataLoader(subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "  miniLoaders.append(SubTrainLoader)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 4 * 4, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1024, 52),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(52, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model         = Net()\n",
        "PATH          = ('./40_epoch_32_batch_SGD_net.pth')\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "finalLayer    = model.classifier[-1]\n",
        "outerShape    = len(finalLayer.weight)\n",
        "innerShape    = len(finalLayer.weight[0])\n",
        "totalWeights  = outerShape * innerShape\n",
        "biasCount     = len(finalLayer.bias)\n",
        "paramCount    = sum(param.numel() for param in finalLayer.parameters())\n",
        "\n",
        "criterion     = nn.CrossEntropyLoss()\n",
        "nn.init.xavier_uniform(finalLayer.weight)\n",
        "print(\"Final layer weight shape,\", (finalLayer.weight).shape)\n",
        "print(\"Final layer bias shape,\", (finalLayer.bias).shape)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "# Define parameters\n",
        "\n",
        "POPULATION_SIZE = 100\n",
        "LOWER_BOUND     = -1\n",
        "UPPER_BOUND     = 1\n",
        "DIMENSION       = 530\n",
        "dspInterval     = 1\n",
        "iterations      = 100\n",
        "crossProb       = 0.8\n",
        "mutateprob      = .1\n",
        "nElitists       = 1\n",
        "\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMax)\n",
        "\n",
        "def uniform(low, up, size=None):\n",
        "    try:\n",
        "        return [random.uniform(a, b) for a, b in zip(low, up)]\n",
        "    except TypeError:\n",
        "        return [random.uniform(a, b) for a, b in zip([low] * size, [up] * size)]\n",
        "\n",
        "def assign_weights(individual):\n",
        "    particleweightsNP1 = np.array(individual)\n",
        "    particleweightsNP = particleweightsNP1[:totalWeights]\n",
        "    biases = np.array(particleweightsNP1[-biasCount:])\n",
        "    biases = torch.from_numpy(biases).float()\n",
        "    finalLayer.bias = torch.nn.Parameter(biases.float())\n",
        "    reshapedWeights = particleweightsNP.reshape(outerShape,innerShape)\n",
        "    torchWeights = torch.from_numpy(reshapedWeights).float()\n",
        "    finalLayer.weight = torch.nn.Parameter(torchWeights.float())\n",
        "\n",
        "def calcFitness(individual, miniNumber):\n",
        "    assign_weights(individual)\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for data in miniLoaders[miniNumber]:\n",
        "        model.to(device)\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        predicted=model(images)\n",
        "\n",
        "        _, predictions = torch.max(predicted, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predictions == labels).sum().item()\n",
        "    acc = 100*(correct_train/total_train)\n",
        "    return acc,\n",
        "\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_float\", uniform, LOWER_BOUND, UPPER_BOUND, DIMENSION)\n",
        "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.attr_float)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=LOWER_BOUND, up=UPPER_BOUND, eta=20.0)\n",
        "toolbox.register(\"mutate\",tools.mutPolynomialBounded, low=LOWER_BOUND, up=UPPER_BOUND, eta=20.0,  indpb= 1/DIMENSION)\n",
        "\n",
        "# set Roulette Wheel selection  for enviromental selection\n",
        "toolbox.register(\"select\",tools.selRoulette, fit_attr='fitness')\n",
        "toolbox.register(\"evaluate\", calcFitness)\n",
        "\n",
        "generations = []\n",
        "evaluations = []\n",
        "min_fitness = []\n",
        "max_fitness = []\n",
        "avg_fitness = []\n",
        "std_dev = []\n",
        "\n",
        "def main():\n",
        "    #random.seed(64)\n",
        "\n",
        "    # create an initial population of individuals (where\n",
        "    # each individual is a list of integers)\n",
        "    pop = toolbox.population(n=POPULATION_SIZE)\n",
        "    miniCounter = 0\n",
        "\n",
        "    # evaluate the entire population\n",
        "    fitnesses = list(map(lambda ind: toolbox.evaluate(ind, miniCounter), pop))\n",
        "    for ind, fit in zip(pop, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "    print(\"  Evaluated %i individuals\" % len(pop))\n",
        "\n",
        "    # extracting all the fitnesses of\n",
        "    fits = [ind.fitness.values[0] for ind in pop]\n",
        "\n",
        "    # variable keeping track of the number of generations\n",
        "    g = 0\n",
        "\n",
        "    # Begin the evolution\n",
        "    while g < iterations:\n",
        "        g = g + 1\n",
        "        print(\"-- Generation %i --\" % g)\n",
        "\n",
        "        # select the next generation individuals\n",
        "        offspring = tools.selBest(pop, nElitists) + toolbox.select(pop,len(pop)-nElitists)\n",
        "        offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "        # apply crossover and mutation on the offspring\n",
        "        # make pairs of offspring for crossing over\n",
        "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "\n",
        "            # cross two individuals with probability CXPB\n",
        "            if random.random() < crossProb:\n",
        "                toolbox.mate(child1, child2)\n",
        "\n",
        "                # fitness values of the children\n",
        "                # must be recalculated later\n",
        "                del child1.fitness.values\n",
        "                del child2.fitness.values\n",
        "\n",
        "        for mutant in offspring:\n",
        "\n",
        "            # mutate an individual with probability mutateprob\n",
        "            if random.random() < mutateprob:\n",
        "                toolbox.mutate(mutant)\n",
        "                del mutant.fitness.values\n",
        "\n",
        "        # Evaluate the individuals with an invalid fitness\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = map(lambda ind: toolbox.evaluate(ind, miniCounter), invalid_ind)\n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "\n",
        "        # replace pop with offspring\n",
        "        pop[:] = offspring\n",
        "\n",
        "        if g%dspInterval ==0:\n",
        "            # gather all the fitnesses in one list and print the stats\n",
        "            fits = [ind.fitness.values[0] for ind in pop]\n",
        "\n",
        "            length = len(pop)\n",
        "            mean = sum(fits) / length\n",
        "            sum2 = sum(x*x for x in fits)\n",
        "            std = abs(sum2 / length - mean**2)**0.5\n",
        "\n",
        "            # append data to lists\n",
        "            generations.append(g)\n",
        "            evaluations.append(len(pop))\n",
        "            min_fitness.append(min(fits))\n",
        "            max_fitness.append(max(fits))\n",
        "            avg_fitness.append(mean)\n",
        "            std_dev.append(std)\n",
        "\n",
        "            print(\"  Min %s\" % min(fits))\n",
        "            print(\"  Max %s\" % max(fits))\n",
        "            print(\"  Avg %s\" % mean)\n",
        "            print(\"  Std %s\" % std)\n",
        "\n",
        "    print(\"-- End of (successful) evolution --\")\n",
        "\n",
        "    best_ind = tools.selBest(pop, 1)[0]\n",
        "    print(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))\n",
        "    miniCounter += 1\n",
        "\n",
        "    if miniCounter >= (len(miniLoaders)):\n",
        "        miniCounter = 0\n",
        "        print(\"Mini Counter reset!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnM7IRbica2S"
      },
      "outputs": [],
      "source": [
        "# write data to CSV file\n",
        "with open('evolution_stats.csv', 'w', newline='') as csvfile:\n",
        "    fieldnames = ['Generation', 'Evaluations', 'Min Fitness', 'Max Fitness', 'Avg Fitness', 'Std Dev']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for i in range(len(generations)):\n",
        "        writer.writerow({\n",
        "            'Generation': generations[i],\n",
        "            'Evaluations': evaluations[i],\n",
        "            'Min Fitness': min_fitness[i],\n",
        "            'Max Fitness': max_fitness[i],\n",
        "            'Avg Fitness': avg_fitness[i],\n",
        "            'Std Dev': std_dev[i]\n",
        "        })"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.12 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
