{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPf07y2xi7ojTfar6Po7f6M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnnaM-C/computational-intelligence/blob/main/Week9GA_Merge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Set_fiV6QQ",
        "outputId": "7ed46516-2b0d-4850-e1d1-9e209a2964de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deap in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "# Merging GA with Neural network from week 9\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from numpy import genfromtxt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "from sympy.combinatorics.graycode import GrayCode\n",
        "from sympy.combinatorics.graycode import gray_to_bin\n",
        "\n",
        "!pip install deap\n",
        "from deap import creator, base, tools, algorithms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the training data\n",
        "\n",
        "# Import the cancer_TR.dat file\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "data = genfromtxt('cancer_TR.dat', delimiter=' ')\n",
        "x = data[:, 0:9]\n",
        "y = data[:, 9:11]\n",
        "x = torch.as_tensor(x, dtype=torch.double)\n",
        "y = torch.as_tensor(y, dtype=torch.double)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "KosHNAjRWudi",
        "outputId": "7bc1632f-f450-44c9-e54c-aa9edd6c4d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6c366084-a692-4281-96d7-496257a368b1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6c366084-a692-4281-96d7-496257a368b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cancer_TR.dat to cancer_TR (5).dat\n",
            "Saving cancer_tt.dat to cancer_tt (5).dat\n",
            "torch.Size([525, 9])\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        ...,\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input shape: \", x.shape)\n",
        "print(x[0])\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHpftXW-yO5e",
        "outputId": "1e0ca264-774e-49ca-af68-5adc2430b52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape:  torch.Size([525, 9])\n",
            "tensor([0.2000, 0.1000, 0.1000, 0.1000, 0.2000, 0.1000, 0.2000, 0.1000, 0.1000],\n",
            "       dtype=torch.float64)\n",
            "torch.Size([525, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the network\n",
        "class Net(torch.nn.Module):\n",
        "    # initialise one hidden layer and one output layer\n",
        "    def __init__(self, n_feature, n_hidden, n_output):\n",
        "        super(Net, self).__init__()\n",
        "        self.hidden = torch.nn.Linear(n_feature, n_hidden)  # hidden layer\n",
        "        self.out = torch.nn.Linear(n_hidden, n_output)  # output layer\n",
        "\n",
        "    # connect up the layers: the input passes through the hidden, then the sigmoid, then the output layer\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.hidden(x))  # activation function for hidden layer\n",
        "        print(\"X: \", x)\n",
        "        # x = x.unsqueeze(0)\n",
        "        # x = torch.flatten(x, start_dim=1)\n",
        "        x=x.view(x.size(0), -1)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "S9Q2IfV-XaC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a network to use for the GA algorithm\n",
        "\n",
        "\n",
        "# There are 2 classes to output and 9 input features\n",
        "net = Net(n_feature=9, n_hidden=5, n_output=2)  # define the network\n",
        "print(net)  # net architecture\n",
        "\n",
        "print((net.hidden.weight).shape)\n",
        "print((net.out.weight).shape)\n",
        "print((net.hidden.bias).shape)\n",
        "print((net.out.bias).shape)\n",
        "\n",
        "paramCount = sum(param.numel() for param in net.parameters())\n",
        "\n",
        "print(paramCount) # 62 decision variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJoZSnlYXcYu",
        "outputId": "ed9ec90a-ace3-4681-97cb-495ac25a3298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (hidden): Linear(in_features=9, out_features=5, bias=True)\n",
            "  (out): Linear(in_features=5, out_features=2, bias=True)\n",
            ")\n",
            "torch.Size([5, 9])\n",
            "torch.Size([2, 5])\n",
            "torch.Size([5])\n",
            "torch.Size([2])\n",
            "62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GA Evaluation function\n",
        "\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# TODO: FIX FROM:TO for weights\n",
        "\n",
        "def calcFitness(individual):\n",
        "  # print(\"Individual: \", individual)\n",
        "\n",
        "  weights=separatevariables(individual)\n",
        "  weights = np.asarray(weights)\n",
        "  print(\"Weights: \", len(weights))\n",
        "  # x = torch.tensor(x, dtype=torch.double)\n",
        "  # y = torch.tensor(y, dtype=torch.double)\n",
        "  # print(weights) # Length: 2, but we need more to be able to reshape! Change number of decision vars so it is enough for weights + biases!?\n",
        "\n",
        "  # First 45 numbers\n",
        "  net.hidden.weight=torch.nn.Parameter(torch.from_numpy(weights[0:45].reshape(5,9))) # Shape is (5,9)\n",
        "\n",
        "  net.out.weight=torch.nn.Parameter(torch.from_numpy(weights[45:55].reshape(2,5).T)) # Shape is (2,5)\n",
        "\n",
        "  net.hidden.bias=torch.nn.Parameter(torch.from_numpy(weights[55:60])) # Shape is 5\n",
        "\n",
        "  net.out.bias=torch.nn.Parameter(torch.from_numpy(weights[60:])) # Shape is 2\n",
        "\n",
        "  out = net(x) # input x and predict based on x\n",
        "  loss = loss_func(out, y)\n",
        "  return loss.item(),"
      ],
      "metadata": {
        "id": "rufCkKolZLaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GA Body\n",
        "\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "popSize     = 50 #Population size\n",
        "\n",
        "#dimension   = 2 #Numer of decision variable x\n",
        "dimension = 62\n",
        "\n",
        "numOfBits   = 10 #Number of bits in the decision variable\n",
        "iterations  = 100 #Number of generations to be run\n",
        "dspInterval = 10\n",
        "nElitists   = 1 #number of elite individuals selected\n",
        "omega       = 5\n",
        "crossPoints = 2 #variable not used. instead tools.cxTwoPoint\n",
        "crossProb   = 0.6\n",
        "flipProb    = 1. / (dimension * numOfBits) #bit mutate prob\n",
        "mutateprob  = .1 #mutation prob\n",
        "maxnum      = 2**numOfBits #absolute max size of number coded by binary list 1,0,0,1,1,....\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "\n",
        "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
        "\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
        "    toolbox.attr_bool, numOfBits*dimension)\n",
        "\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "toolbox.register(\"evaluate\", calcFitness) # Change this\n",
        "\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "\n",
        "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=flipProb)\n",
        "\n",
        "toolbox.register(\"select\", tools.selRoulette, fit_attr='fitness')\n",
        "\n",
        "# Convert chromosome to real number\n",
        "# input: list binary 1,0 of length numOfBits representing number using gray coding\n",
        "# output: real value\n",
        "def chrom2real(c):\n",
        "    indasstring=''.join(map(str, c))\n",
        "    degray=gray_to_bin(indasstring)\n",
        "    numasint=int(degray, 2) # convert to int from base 2 list\n",
        "    numinrange=-5+10*numasint/maxnum\n",
        "    return numinrange\n",
        "\n",
        "\n",
        "# input: concatenated list of binary variables\n",
        "# output: tuple of real numbers representing those variables\n",
        "def separatevariables(v):\n",
        "    print(len(v))\n",
        "    result = []\n",
        "\n",
        "    # Loop through the range of 0 to the length of v with a step of numOfBits\n",
        "    for i in range(0, len(v), numOfBits):\n",
        "        # Take a chunk of numOfBits elements from v and apply chrom2real\n",
        "        chunk_result = chrom2real(v[i:i + numOfBits])\n",
        "        # Append the result to the final list\n",
        "        result.append(chunk_result)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ybX_fFLbrzy",
        "outputId": "23dd0e89-8e03-4a32-80c1-90ef3952f739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    #random.seed(64)\n",
        "\n",
        "    # create an initial population of individuals (where\n",
        "    # each individual is a list of integers)\n",
        "    pop = toolbox.population(n=popSize)\n",
        "\n",
        "#     for individ in pop:\n",
        "#         sep=separatevariables(individ)\n",
        "#         print(sep[0],sep[1])\n",
        "\n",
        "    # print(\"Pop: \", pop)\n",
        "\n",
        "    # Evaluate the entire population\n",
        "    fitnesses = list(map(toolbox.evaluate, pop))\n",
        "\n",
        "    #print(fitnesses)\n",
        "    for ind, fit in zip(pop, fitnesses):\n",
        "        #print(ind, fit)\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "    print(\"  Evaluated %i individuals\" % len(pop))\n",
        "\n",
        "    # Extracting all the fitnesses of\n",
        "    fits = [ind.fitness.values[0] for ind in pop]\n",
        "\n",
        "    # Variable keeping track of the number of generations\n",
        "    g = 0\n",
        "\n",
        "    # Begin the evolution\n",
        "    while g < iterations:\n",
        "        # A new generation\n",
        "        g = g + 1\n",
        "        print(\"-- Generation %i --\" % g)\n",
        "#         for individ in pop:\n",
        "#             print(individ)\n",
        "\n",
        "        # Select the next generation individuals\n",
        "        offspring = tools.selBest(pop, nElitists) + toolbox.select(pop,len(pop)-nElitists)\n",
        "        # Clone the selected individuals\n",
        "        offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "#         for individ in offspring:\n",
        "#             print(individ)\n",
        "\n",
        "\n",
        "        # Apply crossover and mutation on the offspring\n",
        "        # make pairs of offspring for crossing over\n",
        "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "\n",
        "            # cross two individuals with probability CXPB\n",
        "            if random.random() < crossProb:\n",
        "                #print('before crossover ',child1, child2)\n",
        "                toolbox.mate(child1, child2)\n",
        "                #print('after crossover ',child1, child2)\n",
        "\n",
        "                # fitness values of the children\n",
        "                # must be recalculated later\n",
        "                del child1.fitness.values\n",
        "                del child2.fitness.values\n",
        "\n",
        "        for mutant in offspring:\n",
        "\n",
        "            # mutate an individual with probability mutateprob\n",
        "            if random.random() < mutateprob:\n",
        "                toolbox.mutate(mutant)\n",
        "                del mutant.fitness.values\n",
        "\n",
        "        # Evaluate the individuals with an invalid fitness\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = map(toolbox.evaluate, invalid_ind)\n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "\n",
        "        #print(\"  Evaluated %i individuals\" % len(invalid_ind))\n",
        "\n",
        "        # The population is entirely replaced by the offspring\n",
        "        pop[:] = offspring\n",
        "\n",
        "        if g%dspInterval ==0:\n",
        "            # Gather all the fitnesses in one list and print the stats\n",
        "            fits = [ind.fitness.values[0] for ind in pop]\n",
        "\n",
        "            length = len(pop)\n",
        "            mean = sum(fits) / length\n",
        "            sum2 = sum(x*x for x in fits)\n",
        "            std = abs(sum2 / length - mean**2)**0.5\n",
        "\n",
        "            print(\"  Min %s\" % min(fits))\n",
        "            print(\"  Max %s\" % max(fits))\n",
        "            print(\"  Avg %s\" % mean)\n",
        "            print(\"  Std %s\" % std)\n",
        "\n",
        "    print(\"-- End of (successful) evolution --\")\n",
        "\n",
        "    best_ind = tools.selBest(pop, 1)[0]\n",
        "    print(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))\n",
        "    print(\"Decoded x1, x2 is %s, %s\" % (separatevariables(best_ind)))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "6107upRldC64",
        "outputId": "00223f76-b55d-4143-f36f-58a648f7af91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "620\n",
            "Weights:  62\n",
            "tensor([[0.2000, 0.1000, 0.1000,  ..., 0.2000, 0.1000, 0.1000],\n",
            "        [0.2000, 0.1000, 0.1000,  ..., 0.3000, 0.1000, 0.1000],\n",
            "        [0.5000, 0.1000, 0.1000,  ..., 0.2000, 0.1000, 0.1000],\n",
            "        ...,\n",
            "        [0.5000, 0.8000, 0.9000,  ..., 0.7000, 0.1000, 0.1000],\n",
            "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
            "        [0.4000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000]],\n",
            "       dtype=torch.float64)\n",
            "X:  tensor([[ 0.0000,  0.0000,  2.8564,  0.1025,  4.3740],\n",
            "        [ 0.0000,  0.0000,  3.2363,  0.5498,  4.7939],\n",
            "        [ 0.0000,  0.0000,  2.3027,  0.0000,  5.3232],\n",
            "        ...,\n",
            "        [ 0.0000,  4.9336, 12.4443,  2.9336,  7.1631],\n",
            "        [ 0.0000,  0.0000,  4.2959,  0.0332,  4.0010],\n",
            "        [ 0.0000,  0.0000,  2.1074,  0.0000,  4.5869]], dtype=torch.float64,\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-77-dad968abd1b6>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  xx = torch.tensor(x, dtype=torch.double)\n",
            "<ipython-input-77-dad968abd1b6>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  yy = torch.tensor(y, dtype=torch.double)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-8aa6fc2a7589>\u001b[0m in \u001b[0;36m<cell line: 101>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-80-8aa6fc2a7589>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Evaluate the entire population\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#print(fitnesses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-77-dad968abd1b6>\u001b[0m in \u001b[0;36mcalcFitness\u001b[0;34m(individual)\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Shape is 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# input x and predict based on x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-ed348be46632>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# x = torch.flatten(x, start_dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x2625 and 2x5)"
          ]
        }
      ]
    }
  ]
}